{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3d18819",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2df2b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('data/cars_datasets_2025.csv', encoding='latin-1')\n",
    "pd.set_option('display.float_format', '{:,.2f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33671b81",
   "metadata": {},
   "source": [
    "View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26e7bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3625e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e36fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6dfe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389e7a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac20d1e1",
   "metadata": {},
   "source": [
    "Check for empty columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4d2a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bda537",
   "metadata": {},
   "source": [
    "Drop Empty columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69efe291",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_columns = df[df.isna().any(axis=1)]\n",
    "df = df.drop(empty_columns.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eeea25b",
   "metadata": {},
   "source": [
    "Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ca75e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()\n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8483fa",
   "metadata": {},
   "source": [
    "Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "047ab016",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(keep=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb71e9f",
   "metadata": {},
   "source": [
    "\n",
    "Rename columns for easier referencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc0fbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "\n",
    "new_columns = ['car_brand', 'car_name', 'engine', 'cc_battery_capacity', 'horsepower', 'total_speed_kmh', '0_100_kmh_performance_secs', 'price', 'fuel_type', 'seats', 'torque_nm']\n",
    "\n",
    "df.columns = new_columns\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae290a7",
   "metadata": {},
   "source": [
    "Split cars with multiple engine types into different rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea25d693",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(names=\"og_id\")\n",
    "\n",
    "cc_re = re.compile(r'([\\d.,]+)\\s*cc\\b', flags=re.I) # find cc values\n",
    "kwh_range = re.compile(r'([\\d.,]+)\\s*[-â€“]\\s*([\\d.,]+)\\s*kwh\\b', re.I) # match kwh ranges: 'x-y kwh'\n",
    "kwh_re = re.compile(r'([\\d.,]+)\\s*kwh\\b', flags=re.I) # match single kwh value: 'x kwh'\n",
    "num_re = re.compile(r'([\\d.,]+)') # any number that hasn't already been matched\n",
    "paren_re = re.compile(r'\\([^)]*\\)') \n",
    "iv_token = re.compile(r'\\b[ivx]\\s*\\d\\b', re.I)\n",
    "\n",
    "general_norm = re.compile(r'\\s*(?:/|,(?=\\s*[A-Za-z])|-(?!\\s*\\d+\\s*kwh))\\s*', re.I)\n",
    "engine_norm = re.compile(r'\\s*/\\s*', re.I)\n",
    "fuel_norm = re.compile(r'\\s*(?:/|,(?=\\s*[A-Za-z]))\\s*', re.I) # ensure fuel doesn't get split by dashes\n",
    "\n",
    "cols_to_split = [\n",
    "    \"engine\",\n",
    "    \"cc_capacity\",\n",
    "    \"kwh_capacity\",\n",
    "    \"horsepower\",\n",
    "    \"0_100_kmh_performance_secs\",\n",
    "    \"fuel_type\",\n",
    "    \"torque_nm\"\n",
    "]\n",
    "\n",
    "# remove commas from regex matches and turn to float\n",
    "def _nums(s):\n",
    "    out = []\n",
    "    for m in s:\n",
    "        try:\n",
    "            out.append(float(m.replace(',', '')))\n",
    "        except Exception:\n",
    "            pass\n",
    "    return out\n",
    "\n",
    "def extract_capacity_lists(val):\n",
    "    s = str(val)\n",
    "    s_lower = s.lower()\n",
    "    s_norm = kwh_range.sub(r'\\1 kwh / \\2 kwh', s_lower) # turn kwh ranges from 'x-y kwh' to 'x kwh' / 'y kwh' for easier splitting later\n",
    "\n",
    "    # place kwh values into a list\n",
    "    kwh_nums = _nums(kwh_re.findall(s_norm))\n",
    "    kwh_list = kwh_nums if kwh_nums else [pd.NA]\n",
    "    \n",
    "    # prepare non-kwh matches\n",
    "    no_kwh = kwh_re.sub(\"\", s_norm)\n",
    "    no_kwh = paren_re.sub(\" \", no_kwh) # strip parenthesis its contents\n",
    "    no_kwh = iv_token.sub(\" \", no_kwh) # strip any i or v matches\n",
    "\n",
    "    cc_nums = _nums(cc_re.findall(no_kwh)) # find cc values\n",
    "    no_kwh_cc = cc_re.sub(\"\", no_kwh) # non-kwh/cc matches\n",
    "\n",
    "    cc_fallback = _nums(num_re.findall(no_kwh_cc)) # if no cc or kwh attached to value, assume it's cc\n",
    "    cc_all = (cc_nums + cc_fallback) if (cc_nums or cc_fallback) else [pd.NA]\n",
    "\n",
    "    return pd.Series([cc_all, kwh_list])\n",
    "\n",
    "def pre_engine(s):\n",
    "    if pd.isna(s):\n",
    "        return s\n",
    "    t = str(s)\n",
    "    t = re.sub(r'\\b(?:or|vs)\\b', ' / ', t, flags=re.I) # standardize splitting engines with '/' instead of 'or' or 'vs'\n",
    "    t = re.sub(r'(?<!\\d)\\s*,\\s*(?!\\d)', ' ', t) # ignores commas in numbers\n",
    "    t = re.sub(r'\\binline\\s*[- ]?\\s*(\\d)\\b', r'inline-\\1', t, flags=re.I) # standardize 'inline 4' as 'inline-4'\n",
    "    t = re.sub(r'\\bi\\s*[- ]?\\s*(\\d)\\b', r'i\\1', t, flags=re.I) # standardize 'i 4' as 'i4'\n",
    "    t = re.sub(r'\\bv\\s*[- ]?\\s*(\\d)\\b', r'v\\1', t, flags=re.I) # standardize 'v 6' as 'v6'\n",
    "    t = re.sub(r'\\s*/\\s*', ' / ', t)\n",
    "    t = re.sub(r'\\s+', ' ', t).strip()\n",
    "    return t\n",
    "\n",
    "# normalize splitting rows with '/'\n",
    "def normalize_and_split(x, norm):\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    s = re.sub(norm, '/', str(x)) # replace separators with '/'\n",
    "    parts = [p.strip() for p in s.split('/') if p.strip()] # strip then split on '/'\n",
    "    return parts if parts else [pd.NA]\n",
    "\n",
    "def _clean_parts(lst):\n",
    "    if not isinstance(lst, list):\n",
    "        return lst\n",
    "    return [re.sub(r'\\s*,\\s*$', '', p).strip() for p in lst]\n",
    "\n",
    "# create cc and kwh capacity columns from cc_batter_capacity column\n",
    "df[[\"cc_capacity\", \"kwh_capacity\"]] = df[\"cc_battery_capacity\"].apply(extract_capacity_lists)\n",
    "df = df.drop(columns=[\"cc_battery_capacity\"]) # drop original column\n",
    "\n",
    "df[\"engine\"] = df[\"engine\"].map(pre_engine)\n",
    "df[\"engine\"] = df[\"engine\"].map(lambda v: normalize_and_split(v, engine_norm))\n",
    "df[\"engine\"] = df[\"engine\"].map(_clean_parts)\n",
    "\n",
    "for col in cols_to_split:\n",
    "    if col in (\"cc_capacity\", \"kwh_capacity\", \"engine\"):\n",
    "        continue\n",
    "    elif col == \"fuel_type\":\n",
    "        pat = fuel_norm\n",
    "    else:\n",
    "        pat = general_norm\n",
    "    df[col] = df[col].map(lambda v: normalize_and_split(v, pat))\n",
    "\n",
    "df[\"_max_splits\"] = df[cols_to_split].apply(lambda r: max(len(r[c]) for c in cols_to_split), axis=1) # determine how many rows to make\n",
    "df = df.loc[df.index.repeat(df[\"_max_splits\"].where(df[\"_max_splits\"] > 1, 1))].copy()\n",
    "df[\"_idx\"] = df.groupby(\"og_id\").cumcount()\n",
    "df[\"_idx\"] = pd.to_numeric(df[\"_idx\"], errors=\"coerce\").fillna(-1).astype(\"Int64\")\n",
    "\n",
    "def take_n_request(row, col):\n",
    "    vals = row[col]\n",
    "    j = min(row[\"_idx\"], len(vals) - 1)\n",
    "    return vals[j]\n",
    "\n",
    "for col in cols_to_split:\n",
    "    df[col] = df.apply(take_n_request, axis=1, col=col) #???\n",
    "\n",
    "# create row_id column consisting of \"og_id\" and \"_idx\" to highlight highlight original row and what variant it is\n",
    "df[\"row_id\"] = df[\"og_id\"].astype(str) + \"-\" + df[\"_idx\"].astype(str)\n",
    "df.insert(0, \"row_id\", df.pop(\"row_id\"))\n",
    "\n",
    "df = df.drop(columns=[\"_max_splits\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23a1696",
   "metadata": {},
   "source": [
    "Address odd characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1370fffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrub_ascii(x):\n",
    "    if isinstance(x, str):\n",
    "        return re.sub(r'[^\\x00-\\x7F]+', '-', x)\n",
    "    return x\n",
    "\n",
    "obj_cols = df.select_dtypes(include=\"object\").columns\n",
    "for col in obj_cols:\n",
    "    df[col] = df[col].map(scrub_ascii)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6946e8a1",
   "metadata": {},
   "source": [
    "Remove non-numerical characters in numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d9fa037",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = (df['price'].str.replace('$', '', case=False).str.replace(',', '', case=False)).str.strip()\n",
    "\n",
    "numeric_cols = [\"horsepower\", \"torque_nm\", \"0_100_kmh_performance_secs\", \"total_speed_kmh\"]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    df[col] = df[col].astype(str)\n",
    "    df[col] = df[col].str.replace(r'(\\d)\\.\\s+(\\d)', r'\\1.\\2', regex=True)\n",
    "    df[col] = df[col].str.replace(r'[A-Za-z/ ]+', '', regex=True)\n",
    "    df[col] = df[col].str.replace(r'[^0-9\\.\\-]', '', regex=True)\n",
    "    df[col] = df[col].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd43c7c",
   "metadata": {},
   "source": [
    "Address range columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aec970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"price\", \"horsepower\", \"torque_nm\", \"0_100_kmh_performance_secs\"]:\n",
    "    df[col] = df[col].astype(str).str.replace(',', '', regex=False).str.strip()\n",
    "    \n",
    "range_re = re.compile(r'-?\\d+(?:\\.\\d+)?')\n",
    "\n",
    "def extract_range(val):\n",
    "    if pd.isna(val):\n",
    "        return pd.Series([np.nan, np.nan])\n",
    "    \n",
    "    s = str(val)\n",
    "    nums = range_re.findall(s)\n",
    "    nums = [float(n) for n in nums] \n",
    "    \n",
    "    if len(nums) == 0:\n",
    "        return pd.Series([np.nan, np.nan])\n",
    "    elif len(nums) == 1:\n",
    "        return pd.Series([nums[0], nums[0]])\n",
    "    else:\n",
    "        a, b = nums[0], nums[1]\n",
    "        return pd.Series([min(a, b), max(a, b)])\n",
    "    \n",
    "def extract_range_performance(val):\n",
    "    if pd.isna(val):\n",
    "        return pd.Series([np.nan, np.nan])\n",
    "    \n",
    "    s = str(val)\n",
    "    nums = range_re.findall(s)\n",
    "    nums = [float(n) for n in nums]\n",
    "\n",
    "    if len(nums) == 0:\n",
    "        return pd.Series([np.nan, np.nan])\n",
    "    \n",
    "    realistic = [n for n in nums if n > 0]\n",
    "\n",
    "    if len(realistic) == 0:\n",
    "        realistic = nums\n",
    "\n",
    "    if len(realistic) == 1:\n",
    "        return pd.Series([realistic[0], realistic[0]])\n",
    "    else:\n",
    "        a, b = realistic[0], realistic[1]\n",
    "        return pd.Series([min(a, b), max(a, b)])\n",
    "    \n",
    "for col in [\"price\", \"horsepower\", \"torque_nm\"]:\n",
    "    new_cols = [f\"{col}_min\", f\"{col}_max\"]\n",
    "    df[new_cols] = df[col].apply(extract_range)\n",
    "\n",
    "df[[\"0_100_kmh_performance_secs_min\",\n",
    "    \"0_100_kmh_performance_secs_max\"]] = (\n",
    "        df[\"0_100_kmh_performance_secs\"].apply(extract_range_performance)\n",
    "    )\n",
    "\n",
    "df = df.drop(columns=[\"price\", \"horsepower\", \"torque_nm\", \"0_100_kmh_performance_secs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1fda3d",
   "metadata": {},
   "source": [
    "Address Seats Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1334ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_seats(val):\n",
    "    if pd.isna(val):\n",
    "        return pd.Series([np.nan, np.nan])\n",
    "    \n",
    "    s = str(val).strip()\n",
    "    if re.fullmatch(r'\\d+', s):\n",
    "        n = int(s)\n",
    "        return pd.Series([n,n])\n",
    "    \n",
    "    add_seats = re.fullmatch(r'(\\d+)\\+(\\d+)', s)\n",
    "    if add_seats:\n",
    "        a, b = int(add_seats.group(1)), int(add_seats.group(2))\n",
    "        total = a + b\n",
    "        return pd.Series([total, total])\n",
    "    \n",
    "    range_seats = re.fullmatch(r'(\\d+)\\s*-\\s*(\\d+)', s)\n",
    "    if range_seats:\n",
    "        a, b = int(range_seats.group(1)), int(range_seats.group(2))\n",
    "        return pd.Series([min(a, b), max(a, b)])\n",
    "    \n",
    "    return pd.Series([np.nan, np.nan])\n",
    "\n",
    "df[['seats_min', 'seats_max']] = df['seats'].apply(format_seats)\n",
    "df = df.drop(columns=[\"seats\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dae8e54",
   "metadata": {},
   "source": [
    "Convert columns to numerical type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2e2adb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "    \"total_speed_kmh\", \n",
    "    \"seats_min\", \"seats_max\",\n",
    "    \"cc_capacity\", \"kwh_capacity\",\n",
    "    \"price_min\", \"price_max\",\n",
    "    \"horsepower_min\", \"horsepower_max\",\n",
    "    \"torque_nm_min\", \"torque_nm_max\",\n",
    "    \"0_100_kmh_performance_secs_min\", \"0_100_kmh_performance_secs_max\"\n",
    "]\n",
    "\n",
    "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30de718c",
   "metadata": {},
   "source": [
    "Check Fuel-Type Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541e2291",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fuel_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824801e3",
   "metadata": {},
   "source": [
    "Normalize and Drop Fuel Type Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed60811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fuel_type'] = df['fuel_type'].str.lower().str.strip()\n",
    "\n",
    "df['fuel_type'] = df['fuel_type'].replace({\n",
    "    'electric': 'electric',\n",
    "    'ev': 'electric',\n",
    "    'plug-in': 'electric',\n",
    "    'hybrid': 'hybrid',\n",
    "    'plug in hybrid': 'hybrid',\n",
    "    'plug-in hybrid': 'hybrid',\n",
    "    'plug in hyrbrid': 'hybrid',\n",
    "    'hybrid (gas + electric)': 'hybrid',\n",
    "    'hybrid (petrol)': 'hybrid',\n",
    "    'petrol': 'petrol',\n",
    "    'gas': 'petrol',\n",
    "    'awd': 'petrol',\n",
    "    'diesel': 'diesel',\n",
    "    'hydrogen': 'hydrogen',\n",
    "    'cng': 'cng',\n",
    "})\n",
    "\n",
    "# only 3 hydrogen and 1 CNG row, not enough to warrant having its own fuel type category so I thought it was best to omit it\n",
    "drop_fuel_types = df[df['fuel_type'].str.lower().isin(['cng', 'hydrogen'])]\n",
    "\n",
    "df = df.drop(drop_fuel_types.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da293cc0",
   "metadata": {},
   "source": [
    "Check Car Brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8728b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ferrari', 'Rolls Royce', 'Ford', 'Mercedes', 'Audi', 'Bmw',\n",
       "       'Aston Martin', 'Bentley', 'Lamborghini', 'Toyota', 'Nissan',\n",
       "       'Volvo', 'Kia', 'Honda', 'Hyundai', 'Mahindra', 'Maruti Suzuki',\n",
       "       'Volkswagen', 'Porsche', 'Cadillac', 'Tata Motors', 'Tesla',\n",
       "       'Jeep', 'Mazda', 'Chevrolet', 'Gmc', 'Peugeot', 'Bugatti',\n",
       "       'Jaguar Land Rover', 'Acura', 'Mitsubishi'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['car_brand'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8085b14",
   "metadata": {},
   "source": [
    "Fix Car Brand Capitalization and Create New Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9b79d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['car_brand'] = (\n",
    "    df['car_brand']\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .str.title()\n",
    ")\n",
    "\n",
    "# assign region to each car brand\n",
    "region_map = {\n",
    "    'Volkswagen': 'Europe', \n",
    "    'Porsche': 'Europe', \n",
    "    'Peugeot': 'Europe', \n",
    "    'Jaguar Land Rover': 'Europe', \n",
    "    'Bmw': 'Europe', \n",
    "    'Lamborghini': 'Europe', \n",
    "    'Audi': 'Europe', \n",
    "    'Mercedes': 'Europe', \n",
    "    'Rolls Royce': 'Europe', \n",
    "    'Volvo': 'Europe',\n",
    "    'Aston Martin': 'Europe', \n",
    "    'Bugatti': 'Europe', \n",
    "    'Ferrari': 'Europe', \n",
    "    'Bentley': 'Europe',\n",
    "    'Nissan': 'Asia', \n",
    "    'Mazda': 'Asia', \n",
    "    'Kia': 'Asia', \n",
    "    'Toyota': 'Asia', \n",
    "    'Mitsubishi': 'Asia', \n",
    "    'Hyundai': 'Asia', \n",
    "    'Acura': 'Asia', \n",
    "    'Honda': 'Asia', \n",
    "    'Maruti Suzuki': 'Asia', \n",
    "    'Tata Motors': 'Asia', \n",
    "    'Mahindra': 'Asia',\n",
    "    'Ford': 'North America', \n",
    "    'Gmc': 'North America', \n",
    "    'Chevrolet': 'North America', \n",
    "    'Tesla': 'North America', \n",
    "    'Cadillac': 'North America', \n",
    "    'Jeep': 'North America'\n",
    "}\n",
    "\n",
    "# create new column for car brand region\n",
    "df['region'] = df['car_brand'].map(region_map).fillna('Other')\n",
    "\n",
    "country_map = {\n",
    "    'Ferrari': 'Italy',\n",
    "    'Rolls Royce': 'United Kingdom',\n",
    "    'Ford': 'United States',\n",
    "    'Mercedes': 'Germany',\n",
    "    'Audi': 'Germany',\n",
    "    'Bmw': 'Germany',\n",
    "    'Aston Martin': 'United Kingdom',\n",
    "    'Bentley': 'United Kingdom',\n",
    "    'Lamborghini': 'Italy',\n",
    "    'Toyota': 'Japan',\n",
    "    'Nissan': 'Japan',\n",
    "    'Volvo': 'Sweden',\n",
    "    'Kia': 'South Korea',\n",
    "    'Honda': 'Japan',\n",
    "    'Hyundai': 'South Korea',\n",
    "    'Mahindra': 'India',\n",
    "    'Maruti Suzuki': 'India',\n",
    "    'Volkswagen': 'Germany',\n",
    "    'Porsche': 'Germany',\n",
    "    'Cadillac': 'United States',\n",
    "    'Tata Motors': 'India',\n",
    "    'Tesla': 'United States',\n",
    "    'Jeep': 'United States',\n",
    "    'Mazda': 'Japan',\n",
    "    'Chevrolet': 'United States',\n",
    "    'Gmc': 'United States',\n",
    "    'Peugeot': 'France',\n",
    "    'Bugatti': 'France',\n",
    "    'Jaguar Land Rover': 'United Kingdom',\n",
    "    'Acura': 'Japan',\n",
    "    'Mitsubishi': 'Japan'\n",
    "}\n",
    "\n",
    "# assign country to each car brand\n",
    "country_map = {\n",
    "    'Ferrari': 'Italy',\n",
    "    'Rolls Royce': 'United Kingdom',\n",
    "    'Ford': 'United States',\n",
    "    'Mercedes': 'Germany',\n",
    "    'Audi': 'Germany',\n",
    "    'Bmw': 'Germany',\n",
    "    'Aston Martin': 'United Kingdom',\n",
    "    'Bentley': 'United Kingdom',\n",
    "    'Lamborghini': 'Italy',\n",
    "    'Toyota': 'Japan',\n",
    "    'Nissan': 'Japan',\n",
    "    'Volvo': 'Sweden',\n",
    "    'Kia': 'South Korea',\n",
    "    'Honda': 'Japan',\n",
    "    'Hyundai': 'South Korea',\n",
    "    'Mahindra': 'India',\n",
    "    'Maruti Suzuki': 'India',\n",
    "    'Volkswagen': 'Germany',\n",
    "    'Porsche': 'Germany',\n",
    "    'Cadillac': 'United States',\n",
    "    'Tata Motors': 'India',\n",
    "    'Tesla': 'United States',\n",
    "    'Jeep': 'United States',\n",
    "    'Mazda': 'Japan',\n",
    "    'Chevrolet': 'United States',\n",
    "    'Gmc': 'United States',\n",
    "    'Peugeot': 'France',\n",
    "    'Bugatti': 'France',\n",
    "    'Jaguar Land Rover': 'United Kingdom',\n",
    "    'Acura': 'Japan',\n",
    "    'Mitsubishi': 'Japan'\n",
    "}\n",
    "\n",
    "# create new column for car brand country\n",
    "df['country'] = df['car_brand'].map(country_map).fillna('Other')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee3d69c",
   "metadata": {},
   "source": [
    "Create Price Tier Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13de8b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 25000, 50000, 100000, 250000, float('inf')]\n",
    "labels = ['Budget', 'Midrange', 'Premium', 'Luxury', 'Supercar']\n",
    "\n",
    "df['price_tier'] = pd.cut(df['price_max'], bins=bins, labels=labels, right=True)\n",
    "\n",
    "df.groupby('price_tier', observed=True).agg(\n",
    "    avg_price=('price_max', 'mean'),\n",
    "    avg_hp=('horsepower_max', 'mean'),\n",
    "    avg_performance=('0_100_kmh_performance_secs_min', 'mean'),\n",
    "    avg_torque=('torque_nm_max', 'mean'),\n",
    "    avg_cc_capacity=('cc_capacity', 'mean'),\n",
    "    avg_total_speed=('total_speed_kmh', 'mean'),\n",
    "    avg_seats=('seats_max','mean'),\n",
    "    diesel=('fuel_type', lambda x: (x.str.lower() == 'diesel').sum()),\n",
    "    petrol=('fuel_type', lambda x: (x.str.lower() == 'petrol').sum()),\n",
    "    hybrid=('fuel_type', lambda x: (x.str.lower() == 'hybrid').sum()),\n",
    "    electric=('fuel_type', lambda x: (x.str.lower() == 'electric').sum()),\n",
    "    europe=('region', lambda x: (x.str.lower() == 'europe').sum()),\n",
    "    asia=('region', lambda x: (x.str.lower() == 'asia').sum()),\n",
    "    america=('region', lambda x: (x.str.lower() == 'north america').sum()),\n",
    "    car_count=('price_max', 'count')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6b0af27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cars_dataset_2025_cleaned.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
