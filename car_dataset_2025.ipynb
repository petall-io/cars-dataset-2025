{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2afdde8f",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "This notebook documents the full data processing steps used to prepare the dataset for analysis and visualization in Tableau Public."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d18819",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddd8c28",
   "metadata": {},
   "source": [
    "### Import and Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2df2b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('data/cars_datasets_2025.csv', encoding='latin-1')\n",
    "pd.set_option('display.float_format', '{:,.2f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33671b81",
   "metadata": {},
   "source": [
    "### View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26e7bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6dfe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac20d1e1",
   "metadata": {},
   "source": [
    "### Empty Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52be6112",
   "metadata": {},
   "source": [
    "#### Check for empty columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4d2a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bda537",
   "metadata": {},
   "source": [
    "#### Drop Empty columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "69efe291",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_columns = df[df.isna().any(axis=1)]\n",
    "df = df.drop(empty_columns.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986cefcb",
   "metadata": {},
   "source": [
    "### Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eeea25b",
   "metadata": {},
   "source": [
    "#### Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ca75e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()\n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8483fa",
   "metadata": {},
   "source": [
    "#### Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "047ab016",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(keep=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb71e9f",
   "metadata": {},
   "source": [
    "### Renaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889e9737",
   "metadata": {},
   "source": [
    "Rename columns for easier referencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc0fbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "\n",
    "new_columns = [\n",
    "    'car_brand', \n",
    "    'car_name', \n",
    "    'engine', \n",
    "    'cc_battery_capacity', \n",
    "    'horsepower', \n",
    "    'total_speed_kmh', \n",
    "    '0_100_kmh_performance_secs', \n",
    "    'price', \n",
    "    'fuel_type', \n",
    "    'seats', \n",
    "    'torque_nm'\n",
    "    ]\n",
    "\n",
    "df.columns = new_columns\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3590e22",
   "metadata": {},
   "source": [
    "## Row Splitting\n",
    "Some vehicles list multiple engine, capacity, or performance measures in a single row, but I wanted to split these rows to keep each row unique and specific.\n",
    "This process addresses that issue, ensuring one row per unique engine, fuel, and performance measure, while indicating its original index.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b09a4a",
   "metadata": {},
   "source": [
    "#### Regex and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "aba9deaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_re = re.compile(r'([\\d.,]+)\\s*cc\\b', flags=re.I)\n",
    "kwh_range = re.compile(r'([\\d.,]+)\\s*[-â€“]\\s*([\\d.,]+)\\s*kwh\\b', re.I)\n",
    "kwh_re = re.compile(r'([\\d.,]+)\\s*kwh\\b', flags=re.I)\n",
    "num_re = re.compile(r'([\\d.,]+)')\n",
    "\n",
    "paren_re = re.compile(r'\\([^)]*\\)') \n",
    "iv_token = re.compile(r'\\b[ivx]\\s*\\d\\b', re.I)\n",
    "\n",
    "general_norm = re.compile(r'\\s*(?:/|,(?=\\s*[A-Za-z])|-(?!\\s*\\d+\\s*kwh))\\s*', re.I)\n",
    "engine_norm = re.compile(r'\\s*/\\s*', re.I)\n",
    "fuel_norm = re.compile(r'\\s*(?:/|,(?=\\s*[A-Za-z]))\\s*', re.I)\n",
    "\n",
    "cols_to_split = [\n",
    "    \"engine\",\n",
    "    \"cc_capacity\",\n",
    "    \"kwh_capacity\",\n",
    "    \"horsepower\",\n",
    "    \"0_100_kmh_performance_secs\",\n",
    "    \"fuel_type\",\n",
    "    \"torque_nm\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899b4aed",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0207dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _nums(s):\n",
    "    \"\"\"Turn extracted numeric value(s) into float (removes commas)\"\"\"\n",
    "    out = []\n",
    "    for m in s:\n",
    "        try:\n",
    "            out.append(float(m.replace(',', '')))\n",
    "        except Exception:\n",
    "            pass\n",
    "    return out\n",
    "def extract_capacity_lists(val):\n",
    "    \"\"\"\n",
    "    normalize extracted engine capacities\n",
    "    determine if engine contains CC or kWh values and return a separate list for both\n",
    "    \"\"\"\n",
    "    s = str(val)\n",
    "    s_lower = s.lower()\n",
    "    s_norm = kwh_range.sub(r'\\1 kwh / \\2 kwh', s_lower) \n",
    "   \n",
    "    kwh_nums = _nums(kwh_re.findall(s_norm))\n",
    "    kwh_list = kwh_nums if kwh_nums else [pd.NA]\n",
    "    \n",
    "    no_kwh = kwh_re.sub(\"\", s_norm)\n",
    "    no_kwh = paren_re.sub(\" \", no_kwh)\n",
    "    no_kwh = iv_token.sub(\" \", no_kwh)\n",
    "\n",
    "    cc_nums = _nums(cc_re.findall(no_kwh))\n",
    "    no_kwh_cc = cc_re.sub(\"\", no_kwh)\n",
    "\n",
    "    cc_fallback = _nums(num_re.findall(no_kwh_cc)) # if no cc or kwh attached to value, assume it's cc\n",
    "    cc_all = (cc_nums + cc_fallback) if (cc_nums or cc_fallback) else [pd.NA]\n",
    "\n",
    "    return pd.Series([cc_all, kwh_list])\n",
    "def pre_engine(s):\n",
    "    \"\"\"normalize engine strings to ensure proper splitting\"\"\"\n",
    "    if pd.isna(s):\n",
    "        return s\n",
    "    t = str(s)\n",
    "    t = re.sub(r'\\b(?:or|vs)\\b', ' / ', t, flags=re.I)\n",
    "    t = re.sub(r'(?<!\\d)\\s*,\\s*(?!\\d)', ' ', t) # ignore commas in numbers\n",
    "    t = re.sub(r'\\binline\\s*[- ]?\\s*(\\d)\\b', r'inline-\\1', t, flags=re.I) \n",
    "    t = re.sub(r'\\bi\\s*[- ]?\\s*(\\d)\\b', r'i\\1', t, flags=re.I)\n",
    "    t = re.sub(r'\\bv\\s*[- ]?\\s*(\\d)\\b', r'v\\1', t, flags=re.I)\n",
    "    t = re.sub(r'\\s*/\\s*', ' / ', t)\n",
    "    t = re.sub(r'\\s+', ' ', t).strip()\n",
    "    return t\n",
    "def normalize_and_split(x, norm):\n",
    "    \"\"\"normalize separators and split values into a list\"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    s = re.sub(norm, '/', str(x))\n",
    "    parts = [p.strip() for p in s.split('/') if p.strip()]\n",
    "    return parts if parts else [pd.NA]\n",
    "def _clean_parts(lst):\n",
    "    \"\"\"clean trailing punctuation and whitespace from split values\"\"\"\n",
    "    if not isinstance(lst, list):\n",
    "        return lst\n",
    "    return [re.sub(r'\\s*,\\s*$', '', p).strip() for p in lst]\n",
    "def take_n_request(row, col):\n",
    "    \"\"\"assign correct variant value for this row based on _idx\"\"\"\n",
    "    vals = row[col]\n",
    "    j = min(row[\"_idx\"], len(vals) - 1)\n",
    "    return vals[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d48e6c",
   "metadata": {},
   "source": [
    "#### Reset Index and Extract Capacities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a95ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(names=\"og_id\")\n",
    "df[[\"cc_capacity\", \"kwh_capacity\"]] = df[\"cc_battery_capacity\"].apply(extract_capacity_lists)\n",
    "df = df.drop(columns=[\"cc_battery_capacity\"])\n",
    "\n",
    "df[['cc_capacity','kwh_capacity']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2db181",
   "metadata": {},
   "source": [
    "#### Normalize Engine into Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "73cd9a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"engine\"] = df[\"engine\"].map(pre_engine)\n",
    "df[\"engine\"] = df[\"engine\"].map(lambda v: normalize_and_split(v, engine_norm))\n",
    "df[\"engine\"] = df[\"engine\"].map(_clean_parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4d3186",
   "metadata": {},
   "source": [
    "#### Normalize Remaining Columns into Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a784f473",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols_to_split:\n",
    "    if col in (\"cc_capacity\", \"kwh_capacity\", \"engine\"):\n",
    "        continue\n",
    "    elif col == \"fuel_type\":\n",
    "        pat = fuel_norm\n",
    "    else:\n",
    "        pat = general_norm\n",
    "    df[col] = df[col].map(lambda v: normalize_and_split(v, pat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005d6fe6",
   "metadata": {},
   "source": [
    "#### Determine Number of Splits and Index Rows Accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "4beda4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"_max_splits\"] = df[cols_to_split].apply(\n",
    "    lambda r: max(len(r[c]) for c in cols_to_split), \n",
    "    axis=1\n",
    "    )\n",
    "\n",
    "df = df.loc[df.index.repeat(df[\"_max_splits\"].where(df[\"_max_splits\"] > 1, 1))].copy()\n",
    "df[\"_idx\"] = df.groupby(\"og_id\").cumcount()\n",
    "df[\"_idx\"] = pd.to_numeric(df[\"_idx\"], errors=\"coerce\").fillna(-1).astype(\"Int64\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62e52f5",
   "metadata": {},
   "source": [
    "#### Align Variant Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "b643c3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols_to_split:\n",
    "    df[col] = df.apply(take_n_request, axis=1, col=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ad8485",
   "metadata": {},
   "source": [
    "#### Create 'row_id' Column and Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "69626b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"row_id\"] = df[\"og_id\"].astype(str) + \"-\" + df[\"_idx\"].astype(str)\n",
    "df.insert(0, \"row_id\", df.pop(\"row_id\"))\n",
    "\n",
    "df = df.drop(columns=[\"_max_splits\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d5a481",
   "metadata": {},
   "source": [
    "## Additional Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23a1696",
   "metadata": {},
   "source": [
    "### Address odd characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "1370fffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrub_ascii(x):\n",
    "    if isinstance(x, str):\n",
    "        return re.sub(r'[^\\x00-\\x7F]+', '-', x)\n",
    "    return x\n",
    "\n",
    "obj_cols = df.select_dtypes(include=\"object\").columns\n",
    "for col in obj_cols:\n",
    "    df[col] = df[col].map(scrub_ascii)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6946e8a1",
   "metadata": {},
   "source": [
    "### Remove non-numerical characters in numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "1d9fa037",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = (df['price'].str.replace('$', '', case=False).str.replace(',', '', case=False)).str.strip()\n",
    "\n",
    "numeric_cols = [\"horsepower\", \"torque_nm\", \"0_100_kmh_performance_secs\", \"total_speed_kmh\"]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    df[col] = df[col].astype(str)\n",
    "    df[col] = df[col].str.replace(r'(\\d)\\.\\s+(\\d)', r'\\1.\\2', regex=True)\n",
    "    df[col] = df[col].str.replace(r'[A-Za-z/ ]+', '', regex=True)\n",
    "    df[col] = df[col].str.replace(r'[^0-9\\.\\-]', '', regex=True)\n",
    "    df[col] = df[col].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034b5eaa",
   "metadata": {},
   "source": [
    "## Range Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd43c7c",
   "metadata": {},
   "source": [
    "#### Numeric range columns\n",
    "- create separate 'min' and 'max' ranges for these numeric columns for easier analysis\n",
    "- columns with no range will have the same 'min' and 'max' value for both columns\n",
    "- analysis will be conducted using max ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aec970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"price\", \"horsepower\", \"torque_nm\", \"0_100_kmh_performance_secs\"]:\n",
    "    df[col] = df[col].astype(str).str.replace(',', '', regex=False).str.strip()\n",
    "    \n",
    "range_re = re.compile(r'-?\\d+(?:\\.\\d+)?')\n",
    "\n",
    "def extract_range(val):\n",
    "    if pd.isna(val):\n",
    "        return pd.Series([np.nan, np.nan])\n",
    "    \n",
    "    s = str(val)\n",
    "    nums = range_re.findall(s)\n",
    "    nums = [float(n) for n in nums] \n",
    "    \n",
    "    if len(nums) == 0:\n",
    "        return pd.Series([np.nan, np.nan])\n",
    "    elif len(nums) == 1:\n",
    "        return pd.Series([nums[0], nums[0]])\n",
    "    else:\n",
    "        a, b = nums[0], nums[1]\n",
    "        return pd.Series([min(a, b), max(a, b)])\n",
    "def extract_range_performance(val):\n",
    "    if pd.isna(val):\n",
    "        return pd.Series([np.nan, np.nan])\n",
    "    \n",
    "    s = str(val)\n",
    "    nums = range_re.findall(s)\n",
    "    nums = [float(n) for n in nums]\n",
    "\n",
    "    if len(nums) == 0:\n",
    "        return pd.Series([np.nan, np.nan])\n",
    "    \n",
    "    realistic = [n for n in nums if n > 0]\n",
    "\n",
    "    if len(realistic) == 0:\n",
    "        realistic = nums\n",
    "\n",
    "    if len(realistic) == 1:\n",
    "        return pd.Series([realistic[0], realistic[0]])\n",
    "    else:\n",
    "        a, b = realistic[0], realistic[1]\n",
    "        return pd.Series([min(a, b), max(a, b)])\n",
    "    \n",
    "for col in [\"price\", \"horsepower\", \"torque_nm\"]:\n",
    "    new_cols = [f\"{col}_min\", f\"{col}_max\"]\n",
    "    df[new_cols] = df[col].apply(extract_range)\n",
    "\n",
    "df[[\"0_100_kmh_performance_secs_min\",\n",
    "    \"0_100_kmh_performance_secs_max\"]] = (\n",
    "        df[\"0_100_kmh_performance_secs\"].apply(extract_range_performance)\n",
    "    )\n",
    "\n",
    "df = df.drop(columns=[\"price\", \"horsepower\", \"torque_nm\", \"0_100_kmh_performance_secs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1fda3d",
   "metadata": {},
   "source": [
    "#### Seats Column\n",
    "- some cars have a range of seats depending on the trim level\n",
    "- best to create a min and max column for potential analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "a1334ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_seats(val):\n",
    "    if pd.isna(val):\n",
    "        return pd.Series([np.nan, np.nan])\n",
    "    \n",
    "    s = str(val).strip()\n",
    "    if re.fullmatch(r'\\d+', s):\n",
    "        n = int(s)\n",
    "        return pd.Series([n,n])\n",
    "    \n",
    "    add_seats = re.fullmatch(r'(\\d+)\\+(\\d+)', s)\n",
    "    if add_seats:\n",
    "        a, b = int(add_seats.group(1)), int(add_seats.group(2))\n",
    "        total = a + b\n",
    "        return pd.Series([total, total])\n",
    "    \n",
    "    range_seats = re.fullmatch(r'(\\d+)\\s*-\\s*(\\d+)', s)\n",
    "    if range_seats:\n",
    "        a, b = int(range_seats.group(1)), int(range_seats.group(2))\n",
    "        return pd.Series([min(a, b), max(a, b)])\n",
    "    \n",
    "    return pd.Series([np.nan, np.nan])\n",
    "\n",
    "df[['seats_min', 'seats_max']] = df['seats'].apply(format_seats)\n",
    "df = df.drop(columns=[\"seats\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e632bd",
   "metadata": {},
   "source": [
    "## Additional Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dae8e54",
   "metadata": {},
   "source": [
    "#### Convert columns to numerical type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a2e2adb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "    \"total_speed_kmh\", \n",
    "    \"seats_min\", \"seats_max\",\n",
    "    \"cc_capacity\", \"kwh_capacity\",\n",
    "    \"price_min\", \"price_max\",\n",
    "    \"horsepower_min\", \"horsepower_max\",\n",
    "    \"torque_nm_min\", \"torque_nm_max\",\n",
    "    \"0_100_kmh_performance_secs_min\", \"0_100_kmh_performance_secs_max\"\n",
    "]\n",
    "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e199cc",
   "metadata": {},
   "source": [
    "### Fuel Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30de718c",
   "metadata": {},
   "source": [
    "#### Check Fuel-Type Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541e2291",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fuel_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824801e3",
   "metadata": {},
   "source": [
    "#### Normalize and Drop Fuel Type Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "ed60811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fuel_type'] = df['fuel_type'].str.lower().str.strip()\n",
    "\n",
    "df['fuel_type'] = df['fuel_type'].replace({\n",
    "    'electric': 'electric',\n",
    "    'ev': 'electric',\n",
    "    'plug-in': 'electric',\n",
    "    'hybrid': 'hybrid',\n",
    "    'plug in hybrid': 'hybrid',\n",
    "    'plug-in hybrid': 'hybrid',\n",
    "    'plug in hyrbrid': 'hybrid',\n",
    "    'hybrid (gas + electric)': 'hybrid',\n",
    "    'hybrid (petrol)': 'hybrid',\n",
    "    'petrol': 'petrol',\n",
    "    'gas': 'petrol',\n",
    "    'awd': 'petrol',\n",
    "    'diesel': 'diesel',\n",
    "    'hydrogen': 'hydrogen',\n",
    "    'cng': 'cng',\n",
    "})\n",
    "# only 3 hydrogen and 1 CNG row, not enough to warrant having its own fuel type category so I thought it was best to omit it\n",
    "drop_fuel_types = df[df['fuel_type'].str.lower().isin(['cng', 'hydrogen'])]\n",
    "\n",
    "df = df.drop(drop_fuel_types.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c7912e",
   "metadata": {},
   "source": [
    "### Car Brands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da293cc0",
   "metadata": {},
   "source": [
    "#### Check Car Brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8728b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['car_brand'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8085b14",
   "metadata": {},
   "source": [
    "#### Fix Car Brand Capitalization and Map Brands to Region and Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a9b79d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['car_brand'] = (\n",
    "    df['car_brand']\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .str.title()\n",
    ")\n",
    "\n",
    "region_map = {\n",
    "    'Volkswagen': 'Europe', \n",
    "    'Porsche': 'Europe', \n",
    "    'Peugeot': 'Europe', \n",
    "    'Jaguar Land Rover': 'Europe', \n",
    "    'Bmw': 'Europe', \n",
    "    'Lamborghini': 'Europe', \n",
    "    'Audi': 'Europe', \n",
    "    'Mercedes': 'Europe', \n",
    "    'Rolls Royce': 'Europe', \n",
    "    'Volvo': 'Europe',\n",
    "    'Aston Martin': 'Europe', \n",
    "    'Bugatti': 'Europe', \n",
    "    'Ferrari': 'Europe', \n",
    "    'Bentley': 'Europe',\n",
    "    'Nissan': 'Asia', \n",
    "    'Mazda': 'Asia', \n",
    "    'Kia': 'Asia', \n",
    "    'Toyota': 'Asia', \n",
    "    'Mitsubishi': 'Asia', \n",
    "    'Hyundai': 'Asia', \n",
    "    'Acura': 'Asia', \n",
    "    'Honda': 'Asia', \n",
    "    'Maruti Suzuki': 'Asia', \n",
    "    'Tata Motors': 'Asia', \n",
    "    'Mahindra': 'Asia',\n",
    "    'Ford': 'North America', \n",
    "    'Gmc': 'North America', \n",
    "    'Chevrolet': 'North America', \n",
    "    'Tesla': 'North America', \n",
    "    'Cadillac': 'North America', \n",
    "    'Jeep': 'North America'\n",
    "}\n",
    "df['region'] = df['car_brand'].map(region_map).fillna('Other')\n",
    "\n",
    "country_map = {\n",
    "    'Ferrari': 'Italy',\n",
    "    'Rolls Royce': 'United Kingdom',\n",
    "    'Ford': 'United States',\n",
    "    'Mercedes': 'Germany',\n",
    "    'Audi': 'Germany',\n",
    "    'Bmw': 'Germany',\n",
    "    'Aston Martin': 'United Kingdom',\n",
    "    'Bentley': 'United Kingdom',\n",
    "    'Lamborghini': 'Italy',\n",
    "    'Toyota': 'Japan',\n",
    "    'Nissan': 'Japan',\n",
    "    'Volvo': 'Sweden',\n",
    "    'Kia': 'South Korea',\n",
    "    'Honda': 'Japan',\n",
    "    'Hyundai': 'South Korea',\n",
    "    'Mahindra': 'India',\n",
    "    'Maruti Suzuki': 'India',\n",
    "    'Volkswagen': 'Germany',\n",
    "    'Porsche': 'Germany',\n",
    "    'Cadillac': 'United States',\n",
    "    'Tata Motors': 'India',\n",
    "    'Tesla': 'United States',\n",
    "    'Jeep': 'United States',\n",
    "    'Mazda': 'Japan',\n",
    "    'Chevrolet': 'United States',\n",
    "    'Gmc': 'United States',\n",
    "    'Peugeot': 'France',\n",
    "    'Bugatti': 'France',\n",
    "    'Jaguar Land Rover': 'United Kingdom',\n",
    "    'Acura': 'Japan',\n",
    "    'Mitsubishi': 'Japan'\n",
    "}\n",
    "df['country'] = df['car_brand'].map(country_map).fillna('Other')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee3d69c",
   "metadata": {},
   "source": [
    "### Price Tiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57a09fb",
   "metadata": {},
   "source": [
    "Create Price Tiers For Each Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13de8b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 25000, 50000, 100000, 250000, float('inf')]\n",
    "labels = ['Budget', 'Midrange', 'Premium', 'Luxury', 'Supercar']\n",
    "\n",
    "df['price_tier'] = pd.cut(df['price_max'], bins=bins, labels=labels, right=True)\n",
    "\n",
    "df.groupby('price_tier', observed=True).agg(\n",
    "    avg_price=('price_max', 'mean'),\n",
    "    avg_hp=('horsepower_max', 'mean'),\n",
    "    avg_performance=('0_100_kmh_performance_secs_min', 'mean'),\n",
    "    avg_torque=('torque_nm_max', 'mean'),\n",
    "    avg_cc_capacity=('cc_capacity', 'mean'),\n",
    "    avg_total_speed=('total_speed_kmh', 'mean'),\n",
    "    avg_seats=('seats_max','mean'),\n",
    "    diesel=('fuel_type', lambda x: (x.str.lower() == 'diesel').sum()),\n",
    "    petrol=('fuel_type', lambda x: (x.str.lower() == 'petrol').sum()),\n",
    "    hybrid=('fuel_type', lambda x: (x.str.lower() == 'hybrid').sum()),\n",
    "    electric=('fuel_type', lambda x: (x.str.lower() == 'electric').sum()),\n",
    "    europe=('region', lambda x: (x.str.lower() == 'europe').sum()),\n",
    "    asia=('region', lambda x: (x.str.lower() == 'asia').sum()),\n",
    "    america=('region', lambda x: (x.str.lower() == 'north america').sum()),\n",
    "    car_count=('price_max', 'count')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ecb4d1",
   "metadata": {},
   "source": [
    "## Final Dataset Summary\n",
    "- The cleaned dataset contains a single row for each car with variant engine, fuel type, and performance measures\n",
    "- Columns have been renamed and normalized for consistency\n",
    "- Additional, Row Id, Og Id, Variant Id, Range ('min' and max'), Region, Country and Price Tier columns were added for ease and further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0d8969",
   "metadata": {},
   "source": [
    "#### Export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a6b0af27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cars_dataset_2025_cleaned.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
